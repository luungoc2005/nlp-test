{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an intents classification model\n",
    "\n",
    "Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, path\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "BASE_PATH = path.dirname(getcwd())\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "DATA_UTILS = path.join(BASE_PATH, 'common/data_utils.py')\n",
    "TRAIN_PATH = path.join(BASE_PATH, 'kc_data.json')\n",
    "CLASSES_FILE = path.join(BASE_PATH, 'classes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exec(open(DATA_UTILS).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use functions from the utils to extract and preprocess the training data\n",
    "Refer to `kc_data.json` for the sample data format\n",
    "`get_data_pairs` is then used to parse data into a tuple of `([list_of_sentences], [list_of_labels])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_data_pairs(data_from_json(TRAIN_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training the classification model and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_classification.fast_text.model import FastTextWrapper\n",
    "from text_classification.fast_text.train import FastTextLearner\n",
    "from common.callbacks import PrintLoggerCallback\n",
    "\n",
    "model = FastTextWrapper()\n",
    "learner = FastTextLearner(\n",
    "    model,\n",
    "    optimizer_fn='adam'\n",
    "#     optimizer_fn='sgd',\n",
    "#     optimizer_kwargs={'lr': 1e-2, 'momentum': .7}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching to pyro\n",
      "2m 30s (- 2498m 14s) (5 0%) - loss: 1799.3258\n",
      "16m 53s (- 8431m 47s) (10 0%) - loss: 1678.7155\n",
      "19m 29s (- 6477m 4s) (15 0%) - loss: 1614.9474\n",
      "26m 2s (- 6484m 15s) (20 0%) - loss: 1568.4481\n",
      "29m 20s (- 5840m 18s) (25 0%) - loss: 1523.9454\n",
      "32m 4s (- 5314m 26s) (30 0%) - loss: 1488.2136\n",
      "34m 45s (- 4931m 48s) (35 0%) - loss: 1463.3109\n",
      "37m 15s (- 4620m 56s) (40 0%) - loss: 1439.6981\n",
      "40m 6s (- 4416m 23s) (45 0%) - loss: 1397.3102\n",
      "44m 16s (- 4382m 58s) (50 1%) - loss: 1376.4260\n",
      "96m 43s (- 8696m 51s) (55 1%) - loss: 1355.7969\n",
      "160m 59s (- 13254m 39s) (60 1%) - loss: 1317.6580\n",
      "163m 44s (- 12431m 27s) (65 1%) - loss: 1291.8414\n",
      "169m 25s (- 11932m 47s) (70 1%) - loss: 1265.1965\n",
      "174m 45s (- 11476m 4s) (75 1%) - loss: 1235.1915\n",
      "177m 59s (- 10946m 14s) (80 1%) - loss: 1213.7530\n",
      "180m 52s (- 10458m 46s) (85 1%) - loss: 1195.2209\n",
      "183m 47s (- 10026m 44s) (90 1%) - loss: 1169.1114\n",
      "188m 0s (- 9707m 0s) (95 1%) - loss: 1132.9888\n",
      "190m 56s (- 9356m 13s) (100 2%) - loss: 1120.2986\n",
      "401m 47s (- 18731m 29s) (105 2%) - loss: 1084.4117\n",
      "405m 7s (- 18009m 22s) (110 2%) - loss: 1065.2409\n",
      "407m 55s (- 17327m 52s) (115 2%) - loss: 1047.2404\n",
      "410m 42s (- 16702m 9s) (120 2%) - loss: 1024.8785\n",
      "413m 38s (- 16132m 6s) (125 2%) - loss: 1000.2870\n",
      "416m 39s (- 15608m 25s) (130 2%) - loss: 980.3352\n",
      "421m 58s (- 15206m 56s) (135 2%) - loss: 955.6092\n",
      "424m 50s (- 14748m 16s) (140 2%) - loss: 929.0845\n",
      "427m 54s (- 14327m 44s) (145 2%) - loss: 910.2070\n",
      "490m 59s (- 15875m 19s) (150 3%) - loss: 886.8828\n",
      "494m 6s (- 15444m 55s) (155 3%) - loss: 871.4678\n",
      "496m 57s (- 15032m 58s) (160 3%) - loss: 852.5851\n",
      "499m 47s (- 14645m 21s) (165 3%) - loss: 829.8897\n",
      "502m 43s (- 14283m 8s) (170 3%) - loss: 814.8934\n",
      "506m 18s (- 13959m 46s) (175 3%) - loss: 796.3982\n",
      "509m 43s (- 13649m 20s) (180 3%) - loss: 777.3880\n",
      "512m 56s (- 13350m 19s) (185 3%) - loss: 761.4415\n",
      "516m 5s (- 13065m 19s) (190 3%) - loss: 745.3153\n",
      "519m 46s (- 12807m 56s) (195 3%) - loss: 724.5190\n",
      "522m 31s (- 12540m 44s) (200 4%) - loss: 708.2956\n",
      "525m 30s (- 12291m 54s) (205 4%) - loss: 688.8009\n",
      "528m 12s (- 12048m 4s) (210 4%) - loss: 672.6131\n",
      "530m 48s (- 11813m 34s) (215 4%) - loss: 656.0556\n",
      "533m 47s (- 11597m 58s) (220 4%) - loss: 642.3191\n",
      "536m 53s (- 11394m 11s) (225 4%) - loss: 622.3915\n",
      "540m 30s (- 11209m 39s) (230 4%) - loss: 608.7716\n",
      "543m 51s (- 11027m 33s) (235 4%) - loss: 589.6038\n",
      "547m 29s (- 10858m 42s) (240 4%) - loss: 573.7006\n",
      "551m 49s (- 10709m 51s) (245 4%) - loss: 559.9278\n",
      "556m 1s (- 10564m 21s) (250 5%) - loss: 546.6070\n",
      "559m 59s (- 10420m 11s) (255 5%) - loss: 531.1561\n",
      "563m 46s (- 10277m 58s) (260 5%) - loss: 516.1631\n",
      "567m 31s (- 10140m 27s) (265 5%) - loss: 501.9878\n",
      "571m 12s (- 10006m 50s) (270 5%) - loss: 489.2190\n",
      "574m 34s (- 9872m 12s) (275 5%) - loss: 475.8839\n",
      "577m 42s (- 9738m 38s) (280 5%) - loss: 458.8601\n",
      "581m 18s (- 9617m 2s) (285 5%) - loss: 446.5107\n",
      "585m 31s (- 9509m 48s) (290 5%) - loss: 431.4019\n",
      "589m 50s (- 9407m 27s) (295 5%) - loss: 422.7709\n",
      "593m 25s (- 9297m 6s) (300 6%) - loss: 409.6903\n",
      "597m 5s (- 9191m 11s) (305 6%) - loss: 394.4483\n",
      "600m 25s (- 9083m 48s) (310 6%) - loss: 379.6933\n",
      "603m 45s (- 8979m 35s) (315 6%) - loss: 367.0288\n",
      "606m 54s (- 8876m 3s) (320 6%) - loss: 357.2204\n",
      "610m 12s (- 8777m 34s) (325 6%) - loss: 344.5240\n",
      "613m 25s (- 8681m 0s) (330 6%) - loss: 329.0915\n",
      "616m 35s (- 8586m 14s) (335 6%) - loss: 317.8935\n",
      "619m 48s (- 8495m 1s) (340 6%) - loss: 305.5140\n",
      "623m 1s (- 8406m 18s) (345 6%) - loss: 294.6104\n",
      "625m 56s (- 8316m 4s) (350 7%) - loss: 280.0236\n",
      "628m 40s (- 8225m 56s) (355 7%) - loss: 268.1988\n",
      "631m 28s (- 8139m 4s) (360 7%) - loss: 256.2891\n",
      "634m 7s (- 8052m 27s) (365 7%) - loss: 243.1146\n",
      "636m 43s (- 7967m 36s) (370 7%) - loss: 232.2381\n",
      "639m 16s (- 7884m 27s) (375 7%) - loss: 219.4059\n",
      "641m 54s (- 7804m 10s) (380 7%) - loss: 207.4291\n",
      "644m 43s (- 7728m 17s) (385 7%) - loss: 194.9795\n",
      "647m 10s (- 7649m 50s) (390 7%) - loss: 183.3957\n",
      "649m 37s (- 7573m 34s) (395 7%) - loss: 171.8283\n",
      "652m 2s (- 7498m 28s) (400 8%) - loss: 159.8376\n",
      "654m 25s (- 7424m 56s) (405 8%) - loss: 148.2701\n",
      "656m 50s (- 7353m 28s) (410 8%) - loss: 136.8247\n",
      "659m 16s (- 7283m 52s) (415 8%) - loss: 126.3778\n",
      "661m 41s (- 7215m 34s) (420 8%) - loss: 116.7282\n",
      "664m 5s (- 7148m 49s) (425 8%) - loss: 107.1334\n",
      "704m 1s (- 7482m 21s) (430 8%) - loss: 98.6433\n",
      "714m 39s (- 7499m 44s) (435 8%) - loss: 90.3389\n",
      "717m 9s (- 7432m 22s) (440 8%) - loss: 83.5327\n",
      "719m 38s (- 7366m 10s) (445 8%) - loss: 76.7345\n",
      "722m 2s (- 7300m 38s) (450 9%) - loss: 71.0931\n",
      "724m 27s (- 7236m 39s) (455 9%) - loss: 65.5691\n",
      "726m 52s (- 7173m 59s) (460 9%) - loss: 60.6540\n",
      "729m 19s (- 7112m 54s) (465 9%) - loss: 56.6628\n",
      "731m 42s (- 7052m 24s) (470 9%) - loss: 52.5795\n",
      "734m 8s (- 6993m 36s) (475 9%) - loss: 48.8289\n",
      "736m 33s (- 6935m 55s) (480 9%) - loss: 45.6977\n",
      "738m 57s (- 6879m 7s) (485 9%) - loss: 43.1674\n",
      "741m 27s (- 6824m 22s) (490 9%) - loss: 40.3202\n",
      "743m 50s (- 6769m 45s) (495 9%) - loss: 38.1184\n",
      "746m 14s (- 6716m 7s) (500 10%) - loss: 36.2628\n",
      "748m 46s (- 6664m 52s) (505 10%) - loss: 34.2930\n",
      "751m 8s (- 6612m 58s) (510 10%) - loss: 32.6916\n",
      "753m 31s (- 6562m 18s) (515 10%) - loss: 31.1663\n",
      "755m 54s (- 6512m 23s) (520 10%) - loss: 29.9608\n",
      "758m 16s (- 6463m 24s) (525 10%) - loss: 28.5364\n",
      "760m 39s (- 6415m 20s) (530 10%) - loss: 27.5339\n",
      "763m 3s (- 6368m 22s) (535 10%) - loss: 26.5469\n",
      "765m 27s (- 6322m 11s) (540 10%) - loss: 25.7273\n",
      "767m 51s (- 6276m 44s) (545 10%) - loss: 24.9142\n",
      "770m 17s (- 6232m 21s) (550 11%) - loss: 24.0267\n",
      "772m 42s (- 6188m 36s) (555 11%) - loss: 23.4952\n",
      "775m 27s (- 6148m 18s) (560 11%) - loss: 22.8699\n",
      "778m 32s (- 6111m 8s) (565 11%) - loss: 22.1959\n",
      "781m 48s (- 6076m 6s) (570 11%) - loss: 21.6730\n",
      "784m 51s (- 6039m 58s) (575 11%) - loss: 21.2173\n",
      "787m 40s (- 6002m 34s) (580 11%) - loss: 20.7998\n",
      "790m 37s (- 5966m 51s) (585 11%) - loss: 20.3425\n",
      "793m 31s (- 5931m 12s) (590 11%) - loss: 20.0710\n",
      "796m 21s (- 5895m 47s) (595 11%) - loss: 19.8222\n",
      "799m 10s (- 5860m 39s) (600 12%) - loss: 19.3403\n",
      "802m 1s (- 5826m 18s) (605 12%) - loss: 19.1375\n",
      "804m 38s (- 5790m 43s) (610 12%) - loss: 18.7760\n",
      "807m 19s (- 5756m 20s) (615 12%) - loss: 18.6697\n",
      "813m 24s (- 5746m 21s) (620 12%) - loss: 18.3500\n",
      "821m 4s (- 5747m 33s) (625 12%) - loss: 18.1193\n",
      "827m 26s (- 5739m 30s) (630 12%) - loss: 17.9319\n",
      "832m 58s (- 5725m 50s) (635 12%) - loss: 17.7717\n",
      "842m 25s (- 5739m 0s) (640 12%) - loss: 17.5238\n",
      "848m 55s (- 5731m 50s) (645 12%) - loss: 17.3087\n",
      "856m 2s (- 5728m 56s) (650 13%) - loss: 17.1028\n",
      "860m 9s (- 5705m 53s) (655 13%) - loss: 16.9940\n",
      "863m 21s (- 5677m 12s) (660 13%) - loss: 16.9056\n",
      "866m 31s (- 5648m 38s) (665 13%) - loss: 16.7009\n",
      "869m 33s (- 5619m 37s) (670 13%) - loss: 16.5697\n",
      "872m 42s (- 5591m 46s) (675 13%) - loss: 16.4053\n",
      "875m 32s (- 5562m 18s) (680 13%) - loss: 16.3202\n",
      "878m 29s (- 5533m 49s) (685 13%) - loss: 16.2186\n",
      "881m 25s (- 5505m 40s) (690 13%) - loss: 16.1426\n",
      "884m 22s (- 5478m 4s) (695 13%) - loss: 15.9745\n",
      "887m 33s (- 5452m 8s) (700 14%) - loss: 15.8319\n",
      "890m 38s (- 5425m 55s) (705 14%) - loss: 15.7825\n",
      "893m 42s (- 5399m 59s) (710 14%) - loss: 15.7460\n",
      "896m 41s (- 5373m 51s) (715 14%) - loss: 15.6111\n",
      "899m 42s (- 5348m 13s) (720 14%) - loss: 15.4195\n",
      "902m 52s (- 5323m 48s) (725 14%) - loss: 15.4036\n",
      "905m 58s (- 5299m 20s) (730 14%) - loss: 15.3042\n",
      "909m 1s (- 5274m 50s) (735 14%) - loss: 15.1536\n",
      "912m 7s (- 5250m 52s) (740 14%) - loss: 15.0447\n",
      "915m 9s (- 5226m 52s) (745 14%) - loss: 14.9927\n",
      "918m 19s (- 5203m 47s) (750 15%) - loss: 14.9767\n",
      "921m 20s (- 5180m 18s) (755 15%) - loss: 14.7749\n",
      "924m 22s (- 5157m 4s) (760 15%) - loss: 14.6362\n",
      "926m 56s (- 5131m 32s) (765 15%) - loss: 14.6854\n",
      "931m 11s (- 5115m 27s) (770 15%) - loss: 14.6385\n",
      "934m 29s (- 5094m 29s) (775 15%) - loss: 14.5364\n",
      "937m 39s (- 5072m 58s) (780 15%) - loss: 14.4353\n",
      "941m 4s (- 5053m 0s) (785 15%) - loss: 14.3747\n",
      "944m 20s (- 5032m 29s) (790 15%) - loss: 14.2503\n",
      "947m 42s (- 5012m 43s) (795 15%) - loss: 14.2608\n",
      "951m 26s (- 4995m 3s) (800 16%) - loss: 14.0600\n",
      "954m 43s (- 4975m 14s) (805 16%) - loss: 14.0506\n",
      "957m 42s (- 4954m 3s) (810 16%) - loss: 14.0182\n",
      "961m 19s (- 4936m 21s) (815 16%) - loss: 13.9216\n",
      "964m 29s (- 4916m 31s) (820 16%) - loss: 13.9111\n",
      "967m 34s (- 4896m 33s) (825 16%) - loss: 13.7498\n",
      "970m 40s (- 4876m 47s) (830 16%) - loss: 13.7808\n",
      "973m 25s (- 4855m 26s) (835 16%) - loss: 13.7256\n",
      "976m 16s (- 4834m 53s) (840 16%) - loss: 13.6439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979m 8s (- 4814m 34s) (845 16%) - loss: 13.5383\n",
      "981m 37s (- 4792m 37s) (850 17%) - loss: 13.4786\n",
      "984m 17s (- 4771m 46s) (855 17%) - loss: 13.3948\n",
      "987m 34s (- 4754m 6s) (860 17%) - loss: 13.3345\n",
      "990m 41s (- 4735m 51s) (865 17%) - loss: 13.3705\n",
      "993m 54s (- 4718m 10s) (870 17%) - loss: 13.3034\n",
      "997m 13s (- 4701m 14s) (875 17%) - loss: 13.2550\n",
      "1000m 54s (- 4686m 4s) (880 17%) - loss: 13.2396\n",
      "1004m 35s (- 4671m 2s) (885 17%) - loss: 13.1337\n",
      "1008m 17s (- 4656m 17s) (890 17%) - loss: 13.0604\n",
      "1011m 55s (- 4641m 16s) (895 17%) - loss: 13.0747\n",
      "1015m 2s (- 4624m 5s) (900 18%) - loss: 12.9717\n",
      "1018m 7s (- 4606m 53s) (905 18%) - loss: 12.9777\n",
      "1021m 0s (- 4588m 55s) (910 18%) - loss: 12.8838\n",
      "1023m 46s (- 4570m 38s) (915 18%) - loss: 12.8818\n",
      "1026m 45s (- 4553m 27s) (920 18%) - loss: 12.8579\n",
      "1029m 49s (- 4536m 47s) (925 18%) - loss: 12.7876\n",
      "1032m 35s (- 4518m 58s) (930 18%) - loss: 12.6935\n",
      "1035m 8s (- 4500m 23s) (935 18%) - loss: 12.6765\n",
      "1038m 5s (- 4483m 40s) (940 18%) - loss: 12.6250\n",
      "1040m 44s (- 4465m 49s) (945 18%) - loss: 12.5702\n",
      "1043m 23s (- 4448m 8s) (950 19%) - loss: 12.6092\n",
      "1047m 15s (- 4435m 44s) (955 19%) - loss: 12.5214\n",
      "1051m 18s (- 4424m 15s) (960 19%) - loss: 12.4939\n",
      "1055m 25s (- 4413m 7s) (965 19%) - loss: 12.3995\n",
      "1059m 31s (- 4401m 56s) (970 19%) - loss: 12.4056\n",
      "1063m 5s (- 4388m 40s) (975 19%) - loss: 12.3845\n",
      "1065m 54s (- 4372m 24s) (980 19%) - loss: 12.3506\n",
      "1068m 35s (- 4355m 45s) (985 19%) - loss: 12.2324\n",
      "1071m 17s (- 4339m 16s) (990 19%) - loss: 12.2664\n",
      "1073m 53s (- 4322m 34s) (995 19%) - loss: 12.2560\n",
      "1076m 33s (- 4306m 15s) (1000 20%) - loss: 12.1719\n",
      "1079m 10s (- 4289m 50s) (1005 20%) - loss: 12.1761\n",
      "1081m 59s (- 4274m 22s) (1010 20%) - loss: 12.1608\n",
      "1084m 44s (- 4258m 47s) (1015 20%) - loss: 12.0731\n",
      "1087m 7s (- 4241m 55s) (1020 20%) - loss: 12.0854\n",
      "1089m 32s (- 4225m 18s) (1025 20%) - loss: 11.9831\n",
      "1091m 54s (- 4208m 35s) (1030 20%) - loss: 11.9909\n",
      "1094m 14s (- 4191m 56s) (1035 20%) - loss: 11.9705\n",
      "1096m 36s (- 4175m 31s) (1040 20%) - loss: 11.9658\n",
      "1098m 56s (- 4159m 8s) (1045 20%) - loss: 11.9226\n",
      "1101m 17s (- 4142m 56s) (1050 21%) - loss: 11.9280\n",
      "1103m 37s (- 4126m 50s) (1055 21%) - loss: 11.8017\n",
      "1105m 58s (- 4110m 54s) (1060 21%) - loss: 11.8766\n",
      "1108m 20s (- 4095m 9s) (1065 21%) - loss: 11.7696\n",
      "1110m 41s (- 4079m 26s) (1070 21%) - loss: 11.7667\n",
      "1113m 2s (- 4063m 55s) (1075 21%) - loss: 11.6996\n",
      "1115m 23s (- 4048m 28s) (1080 21%) - loss: 11.7043\n",
      "1117m 45s (- 4033m 10s) (1085 21%) - loss: 11.6951\n",
      "1120m 8s (- 4018m 6s) (1090 21%) - loss: 11.6095\n",
      "1122m 30s (- 4003m 5s) (1095 21%) - loss: 11.6315\n",
      "1124m 51s (- 3988m 7s) (1100 22%) - loss: 11.5750\n",
      "1179m 2s (- 4155m 58s) (1105 22%) - loss: 11.5341\n",
      "1181m 39s (- 4141m 5s) (1110 22%) - loss: 11.5392\n",
      "1184m 8s (- 4125m 53s) (1115 22%) - loss: 11.5201\n",
      "1186m 42s (- 4111m 5s) (1120 22%) - loss: 11.4532\n",
      "1189m 12s (- 4096m 8s) (1125 22%) - loss: 11.4462\n",
      "1191m 37s (- 4081m 4s) (1130 22%) - loss: 11.4442\n",
      "1194m 3s (- 4066m 5s) (1135 22%) - loss: 11.4074\n",
      "1196m 25s (- 4051m 2s) (1140 22%) - loss: 11.4099\n",
      "1199m 6s (- 4037m 10s) (1145 22%) - loss: 11.3222\n",
      "1201m 30s (- 4022m 25s) (1150 23%) - loss: 11.3448\n",
      "1203m 56s (- 4007m 55s) (1155 23%) - loss: 11.2991\n",
      "1206m 19s (- 3993m 21s) (1160 23%) - loss: 11.3455\n",
      "1208m 49s (- 3979m 16s) (1165 23%) - loss: 11.2253\n",
      "1211m 11s (- 3964m 50s) (1170 23%) - loss: 11.2527\n",
      "1213m 32s (- 3950m 28s) (1175 23%) - loss: 11.1862\n",
      "1215m 53s (- 3936m 11s) (1180 23%) - loss: 11.2442\n",
      "1218m 18s (- 3922m 14s) (1185 23%) - loss: 11.1969\n",
      "1220m 37s (- 3908m 3s) (1190 23%) - loss: 11.1119\n",
      "1223m 0s (- 3894m 9s) (1195 23%) - loss: 11.0773\n",
      "1225m 21s (- 3880m 18s) (1200 24%) - loss: 11.1472\n",
      "1227m 40s (- 3866m 24s) (1205 24%) - loss: 11.1154\n",
      "1230m 1s (- 3852m 43s) (1210 24%) - loss: 11.0922\n",
      "1232m 20s (- 3839m 0s) (1215 24%) - loss: 10.9812\n",
      "1234m 44s (- 3825m 40s) (1220 24%) - loss: 11.0632\n",
      "1237m 3s (- 3812m 9s) (1225 24%) - loss: 11.0222\n",
      "1239m 27s (- 3798m 59s) (1230 24%) - loss: 11.0299\n",
      "1241m 45s (- 3785m 35s) (1235 24%) - loss: 10.9592\n",
      "1244m 0s (- 3772m 8s) (1240 24%) - loss: 10.9320\n",
      "1246m 16s (- 3758m 49s) (1245 24%) - loss: 10.9179\n",
      "1248m 30s (- 3745m 31s) (1250 25%) - loss: 10.8726\n",
      "1250m 46s (- 3732m 22s) (1255 25%) - loss: 10.8882\n",
      "1253m 1s (- 3719m 16s) (1260 25%) - loss: 10.8334\n",
      "1255m 17s (- 3706m 19s) (1265 25%) - loss: 10.8337\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Interrupted system call at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/libshm/core.cpp:99",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6e655bc46dda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtraining_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPrintLoggerCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/Documents/botbot-nlp/common/wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, training_data, validation_data, epochs, minibatches, epoch_start, batch_size, shuffle, optimize_on_cpu, fp16, loss_scale, gradient_accumulation_steps, callbacks)\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_halt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# For early stopping / skipping batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/botbot-nlp/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/botbot-nlp/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader timed out after {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/botbot-nlp/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/botbot-nlp/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_filename\u001b[0;34m(cls, manager, handle, size)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstorage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_decref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0mshared_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weak_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStorageRef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_decref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Interrupted system call at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/libshm/core.cpp:99"
     ]
    }
   ],
   "source": [
    "learner.fit(\n",
    "    training_data=(X_train, y_train), \n",
    "    epochs=5000, \n",
    "    callbacks=[PrintLoggerCallback(log_every=5, metrics=['loss', 'accuracy'])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(['can i wear tampons after having a baby'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
