{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an intents classification model\n",
    "\n",
    "Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, path\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "BASE_PATH = path.dirname(getcwd())\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "DATA_UTILS = path.join(BASE_PATH, 'common/data_utils.py')\n",
    "TRAIN_PATH = path.join(BASE_PATH, 'kc_data.json')\n",
    "CLASSES_FILE = path.join(BASE_PATH, 'classes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exec(open(DATA_UTILS).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use functions from the utils to extract and preprocess the training data\n",
    "Refer to `kc_data.json` for the sample data format\n",
    "`get_data_pairs` is then used to parse data into a tuple of `([list_of_sentences], [list_of_labels])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_data_pairs(data_from_json(TRAIN_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training the classification model and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_classification.ensemble.model import EnsembleWrapper\n",
    "from text_classification.ensemble.train import EnsembleLearner\n",
    "from common.callbacks import PrintLoggerCallback\n",
    "\n",
    "model = EnsembleWrapper()\n",
    "learner = EnsembleLearner(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 7.15212112\n",
      "Iteration 2, loss = 6.73498926\n",
      "Iteration 3, loss = 6.25083492\n",
      "Iteration 4, loss = 5.63322660\n",
      "Iteration 5, loss = 4.96849060\n",
      "Iteration 6, loss = 4.32674778\n",
      "Iteration 7, loss = 3.73926472\n",
      "Iteration 8, loss = 3.21950214\n",
      "Iteration 9, loss = 2.78242449\n",
      "Iteration 10, loss = 2.41609985\n",
      "Iteration 11, loss = 2.11374474\n",
      "Iteration 12, loss = 1.86421773\n",
      "Iteration 13, loss = 1.65795315\n",
      "Iteration 14, loss = 1.49096977\n",
      "Iteration 15, loss = 1.34877077\n",
      "Iteration 16, loss = 1.23000708\n",
      "Iteration 17, loss = 1.12976384\n",
      "Iteration 18, loss = 1.04382110\n",
      "Iteration 19, loss = 0.96702607\n",
      "Iteration 20, loss = 0.90271917\n",
      "Iteration 21, loss = 0.84549743\n",
      "Iteration 22, loss = 0.79435219\n",
      "Iteration 23, loss = 0.75078155\n",
      "Iteration 24, loss = 0.71045494\n",
      "Iteration 25, loss = 0.67514928\n",
      "Iteration 26, loss = 0.64275244\n",
      "Iteration 27, loss = 0.61088806\n",
      "Iteration 28, loss = 0.58426456\n",
      "Iteration 29, loss = 0.55798435\n",
      "Iteration 30, loss = 0.53804530\n",
      "Iteration 31, loss = 0.51865630\n",
      "Iteration 32, loss = 0.49792554\n",
      "Iteration 33, loss = 0.48077754\n",
      "Iteration 34, loss = 0.46341981\n",
      "Iteration 35, loss = 0.44905153\n",
      "Iteration 36, loss = 0.43675418\n",
      "Iteration 37, loss = 0.42174286\n",
      "Iteration 38, loss = 0.41141540\n",
      "Iteration 39, loss = 0.39983132\n",
      "Iteration 40, loss = 0.38546568\n",
      "Iteration 41, loss = 0.37720723\n",
      "Iteration 42, loss = 0.36868526\n",
      "Iteration 43, loss = 0.35984901\n",
      "Iteration 44, loss = 0.35433040\n",
      "Iteration 45, loss = 0.34310767\n",
      "Iteration 46, loss = 0.33567019\n",
      "Iteration 47, loss = 0.33006949\n",
      "Iteration 48, loss = 0.32267953\n",
      "Iteration 49, loss = 0.31894334\n",
      "Iteration 50, loss = 0.30980473\n",
      "Iteration 51, loss = 0.30482080\n",
      "Iteration 52, loss = 0.30012676\n",
      "Iteration 53, loss = 0.29470164\n",
      "Iteration 54, loss = 0.29019051\n",
      "Iteration 55, loss = 0.28828639\n",
      "Iteration 56, loss = 0.28184774\n",
      "Iteration 57, loss = 0.27948989\n",
      "Iteration 58, loss = 0.27335796\n",
      "Iteration 59, loss = 0.27216390\n",
      "Iteration 60, loss = 0.26761215\n",
      "Iteration 61, loss = 0.26417066\n",
      "Iteration 62, loss = 0.26273445\n",
      "Iteration 63, loss = 0.25864888\n",
      "Iteration 64, loss = 0.25588672\n",
      "Iteration 65, loss = 0.25403476\n",
      "Iteration 66, loss = 0.25177272\n",
      "Iteration 67, loss = 0.24794429\n",
      "Iteration 68, loss = 0.24477271\n",
      "Iteration 69, loss = 0.24217064\n",
      "Iteration 70, loss = 0.23847778\n",
      "Iteration 71, loss = 0.23711237\n",
      "Iteration 72, loss = 0.23646878\n",
      "Iteration 73, loss = 0.23354988\n",
      "Iteration 74, loss = 0.23225049\n",
      "Iteration 75, loss = 0.22850236\n",
      "Iteration 76, loss = 0.22741920\n",
      "Iteration 77, loss = 0.22570767\n",
      "Iteration 78, loss = 0.22346911\n",
      "Iteration 79, loss = 0.22208613\n",
      "Iteration 80, loss = 0.22161801\n",
      "Iteration 81, loss = 0.21955602\n",
      "Iteration 82, loss = 0.21766189\n",
      "Iteration 83, loss = 0.21621561\n",
      "Iteration 84, loss = 0.21498144\n",
      "Iteration 85, loss = 0.21250813\n",
      "Iteration 86, loss = 0.21713411\n",
      "Iteration 87, loss = 0.21462543\n",
      "Iteration 88, loss = 0.21226059\n",
      "Iteration 89, loss = 0.21319319\n",
      "Iteration 90, loss = 0.20803018\n",
      "Iteration 91, loss = 0.20646010\n",
      "Iteration 92, loss = 0.20431378\n",
      "Iteration 93, loss = 0.20531320\n",
      "Iteration 94, loss = 0.20330645\n",
      "Iteration 95, loss = 0.20427655\n",
      "Iteration 96, loss = 0.20205107\n",
      "Iteration 97, loss = 0.20086424\n",
      "Iteration 98, loss = 0.19929518\n",
      "Iteration 99, loss = 0.19900150\n",
      "Iteration 100, loss = 0.19870519\n",
      "Iteration 101, loss = 0.19772786\n",
      "Iteration 102, loss = 0.19699360\n",
      "Iteration 103, loss = 0.19775275\n",
      "Iteration 104, loss = 0.19598585\n",
      "Iteration 105, loss = 0.19352257\n",
      "Iteration 106, loss = 0.19392220\n",
      "Iteration 107, loss = 0.19486658\n",
      "Iteration 108, loss = 0.19227559\n",
      "Iteration 109, loss = 0.19178980\n",
      "Iteration 110, loss = 0.19095885\n",
      "Iteration 111, loss = 0.19016744\n",
      "Iteration 112, loss = 0.19046755\n",
      "Iteration 113, loss = 0.18954304\n",
      "Iteration 114, loss = 0.18714113\n",
      "Iteration 115, loss = 0.18999917\n",
      "Iteration 116, loss = 0.18647612\n",
      "Iteration 117, loss = 0.18629702\n",
      "Iteration 118, loss = 0.18425977\n",
      "Iteration 119, loss = 0.18482483\n",
      "Iteration 120, loss = 0.18708451\n",
      "Iteration 121, loss = 0.18567130\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Model score: 0.948127925117\n"
     ]
    }
   ],
   "source": [
    "learner.fit(\n",
    "    training_data=(X_train, y_train),\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(['asdfasdf'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
