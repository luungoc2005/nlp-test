{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an entities recognition model\n",
    "\n",
    "Importing the required code files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, path\n",
    "import sys\n",
    "\n",
    "BASE_PATH = path.dirname(getcwd())\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "from config import START_TAG, STOP_TAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/2359media/Documents/botbot-nlp\n"
     ]
    }
   ],
   "source": [
    "print(BASE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data must be an array that:\n",
    "- Contains tuples of (sentence, tags)\n",
    "- Sentence will be splitted using nltk.wordpunct_tokenize\n",
    "- Tags will be splitted using .split() - hence spaces by default\n",
    "\n",
    "Each entity must be separated into 3 kinds of tag: B- (Begin), I- (Inside) and O- (Outside)\n",
    "\n",
    "_This is to help with separation in the case of consecutive entities_\n",
    "\n",
    "A `dictionary` to translate from these tags into consecutive indices must be defined\n",
    "This dictionary will contain:\n",
    "- The empty token\n",
    "- `START_TAG` and `END_TAG` tokens (imported from global configs - used internally to indicate start and end of sentence)\n",
    "- Entities B-, I-, O- tokens\n",
    "\n",
    "**Sample training data for email recognition:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = [('hi thanh', '- - B-name'), ('hello duc, how are you?', '- - B-name - - - - - - - -')]\n",
    "\n",
    "# tag_to_ix = {'-': 0, '<START>': 1, '<STOP>': 2, 'B-name': 3, 'I-name': 4}\n",
    "\n",
    "training_data = [(\n",
    "    'My email address is at luungoc2005@gmail.com.',\n",
    "    '- - - - - - - - - - B-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL -'\n",
    "), (\n",
    "    'Contact me at contact@2359media.net.',\n",
    "    '- - - - - - B-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL -'\n",
    "), (\n",
    "    'test.email@microsoft.com is a testing email address',\n",
    "    'B-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL - - - - - - - - - -'\n",
    "), (\n",
    "    'Any inquiries email thesloth_197@gmail.com for assistance',\n",
    "    '- - - - - - B-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL - - - -'\n",
    "), (\n",
    "    'Email addresses include test.noreply@gmail.com hello.vietnam@hallo.org contact@rocket.net',\n",
    "    '- - - - - - B-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL - B-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL - B-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL'\n",
    "), (\n",
    "    'Contact: tester@github.com at any hours',\n",
    "    '- - - B-EMAIL I-EMAIL I-EMAIL I-EMAIL I-EMAIL - - - - - -'\n",
    ")]\n",
    "\n",
    "tag_to_ix = {\n",
    "    '-': 1, # O tag but using '-' for readability\n",
    "    'B-EMAIL': 2,\n",
    "    'I-EMAIL': 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entities_recognition.transformer.model import TransformerSequenceTaggerWrapper\n",
    "from entities_recognition.transformer.train import TransformerSequenceTaggerLearner\n",
    "from entities_recognition.transformer.data import TransformerEntitiesRecognitionDataset\n",
    "from common.callbacks import PrintLoggerCallback, EarlyStoppingCallback, ReduceLROnPlateau\n",
    "from common.modules import BertAdam\n",
    "\n",
    "model = TransformerSequenceTaggerWrapper({'tag_to_ix': tag_to_ix})\n",
    "learner = TransformerSequenceTaggerLearner(model)\n",
    "training_data = TransformerEntitiesRecognitionDataset(training_data, tag_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 3s (- 5m 51s) (5 1%) - loss: 15.3277 - accuracy: 0.4459\n",
      "0m 5s (- 4m 21s) (10 2%) - loss: 8.6164 - accuracy: 0.5490\n",
      "0m 7s (- 3m 48s) (15 3%) - loss: 6.5600 - accuracy: 0.5356\n",
      "0m 8s (- 3m 30s) (20 4%) - loss: 7.1209 - accuracy: 0.6956\n",
      "0m 10s (- 3m 21s) (25 5%) - loss: 8.7328 - accuracy: 0.7066\n",
      "0m 12s (- 3m 15s) (30 6%) - loss: 3.3468 - accuracy: 0.6362\n",
      "0m 14s (- 3m 7s) (35 7%) - loss: 2.7418 - accuracy: 0.7275\n",
      "0m 15s (- 3m 2s) (40 8%) - loss: 0.4241 - accuracy: 0.7415\n",
      "0m 17s (- 2m 57s) (45 9%) - loss: 0.7996 - accuracy: 0.6558\n",
      "0m 19s (- 2m 52s) (50 10%) - loss: -3.0843 - accuracy: 0.7146\n",
      "0m 20s (- 2m 48s) (55 11%) - loss: -2.5515 - accuracy: 0.7048\n",
      "0m 22s (- 2m 44s) (60 12%) - loss: -3.1614 - accuracy: 0.6692\n",
      "Monitor value plateaued at `loss` == 0.653759. Applying new learning rate: 0.001000 -> 0.000250\n",
      "0m 24s (- 2m 40s) (65 13%) - loss: -3.7602 - accuracy: 0.6961\n",
      "0m 25s (- 2m 37s) (70 14%) - loss: -4.4008 - accuracy: 0.6961\n",
      "0m 27s (- 2m 34s) (75 15%) - loss: -5.3935 - accuracy: 0.7048\n",
      "0m 29s (- 2m 32s) (80 16%) - loss: -4.9543 - accuracy: 0.6986\n",
      "0m 30s (- 2m 30s) (85 17%) - loss: -5.1613 - accuracy: 0.6924\n",
      "Monitor value plateaued at `loss` == -3.454685. Applying new learning rate: 0.000250 -> 0.000063\n",
      "0m 32s (- 2m 28s) (90 18%) - loss: -4.2091 - accuracy: 0.6924\n",
      "0m 34s (- 2m 25s) (95 19%) - loss: -4.5321 - accuracy: 0.7023\n",
      "0m 35s (- 2m 23s) (100 20%) - loss: -5.7896 - accuracy: 0.7084\n",
      "0m 37s (- 2m 21s) (105 21%) - loss: -5.6346 - accuracy: 0.6924\n",
      "0m 39s (- 2m 19s) (110 22%) - loss: -5.7436 - accuracy: 0.6924\n",
      "Monitor value plateaued at `loss` == -4.913670. Applying new learning rate: 0.000063 -> 0.000016\n",
      "0m 41s (- 2m 17s) (115 23%) - loss: -6.1379 - accuracy: 0.7023\n",
      "0m 42s (- 2m 16s) (120 24%) - loss: 0.1007 - accuracy: 0.6905\n",
      "0m 44s (- 2m 13s) (125 25%) - loss: -5.2087 - accuracy: 0.6961\n",
      "Monitor value plateaued at `loss` == -5.208688. Applying new learning rate: 0.000016 -> 0.000004\n",
      "0m 46s (- 2m 11s) (130 26%) - loss: -5.9309 - accuracy: 0.7146\n",
      "0m 48s (- 2m 9s) (135 27%) - loss: 0.1277 - accuracy: 0.6905\n",
      "0m 49s (- 2m 8s) (140 28%) - loss: -2.8398 - accuracy: 0.7709\n",
      "0m 51s (- 2m 6s) (145 28%) - loss: -6.1547 - accuracy: 0.7146\n",
      "0m 53s (- 2m 4s) (150 30%) - loss: -2.6452 - accuracy: 0.7807\n",
      "Minimum learning rate reached. Early stopping\n"
     ]
    }
   ],
   "source": [
    "learner.fit(\n",
    "    training_data=training_data,\n",
    "    epochs=500,\n",
    "    batch_size=2,\n",
    "    callbacks=[\n",
    "        PrintLoggerCallback(log_every=5),\n",
    "        ReduceLROnPlateau(reduce_factor=4, patience=10)\n",
    "#         EarlyStoppingCallback()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " [[{'name': 'EMAIL', 'values': ['test.email@microsoft.com']}]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.utils import wordpunct_space_tokenize\n",
    "model([wordpunct_space_tokenize('test.email@microsoft.com is a testing email address')])\n",
    "# model([wordpunct_space_tokenize('Any inquiries email thesloth_197@gmail.com for assistance')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model accuracy by using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
